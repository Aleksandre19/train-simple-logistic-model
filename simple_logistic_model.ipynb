{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d65135b-afbc-4a02-b184-23c55ce2fdff",
   "metadata": {},
   "source": [
    "# Training a simple logistic regression model\n",
    "\n",
    "This project builds a logistic regression model to predict whether a student will be admitted to graduate school based on their academic profile. The process starts by preparing our data through several key transformations: one-hot encoding converts school ranks into separate binary columns, while z-score standardization puts GRE scores and GPAs on comparable scales.\n",
    "\n",
    "The data is then split into training (90%) and testing (10%) sets to properly evaluate the model's performance. The logistic regression model learns by iteratively adjusting weights through gradient descent over 1000 epochs. During each epoch, it calculates admission probabilities using the sigmoid function, compares these predictions to actual admission results, and updates the weights to minimize prediction errors.\n",
    "\n",
    "The `learning rate` of `0.5` controls how quickly the model adapts to errors, while regular loss calculations help monitor if the model is improving. The final model makes admission predictions by converting probability scores (between `0` and `1`) into yes/no decisions using a `0.5` threshold, achieving reasonable accuracy on previously unseen test data.\n",
    "\n",
    "This approach provides an automated way to assess admission chances based on academic metrics, though it's important to note it's a simplified model of what is typically a more complex admission process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9cb691-201a-4570-b43d-18712da3818a",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed266497-7a90-429f-9db1-725e2665c6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c1a4a-8b12-4850-ba5c-bd931cebd1b8",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ce9be013-d920-4f9e-8fb4-3ffc3a38c7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4\n",
       "5      1  760  3.00     2\n",
       "6      1  560  2.98     1\n",
       "7      0  400  3.08     2\n",
       "8      1  540  3.39     3\n",
       "9      0  700  3.92     2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = 'labs/train_nn_on_graduate_school_admissions_data'\n",
    "admissions = pd.read_csv(f\"{folder}/binary.csv\");\n",
    "admissions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8176a8b-4187-4664-945c-4b0b53029297",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "One-hot encoding was used to convert the `'rank'` column into a format that machine learning models can better understand. Since models work with numbers, but our rank categories `(1, 2, 3, 4)` are just labels for different school ranks, we need to transform them so the model doesn't think `rank 4` is \"twice as good\" as rank 2.\n",
    "\n",
    "The code creates separate columns for each rank `(rank_1, rank_2, rank_3, rank_4)`, puts a 1 in the column matching a student's school rank, and 0 in all others. For instance, a rank 2 school gets marked as 0-1-0-0 across these columns. This ensures the model treats each rank independently, without assuming any numerical relationships between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94f99f64-e077-4c4c-8a34-93095c6f466c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
       "0      0  380  3.61   False   False    True   False\n",
       "1      1  660  3.67   False   False    True   False\n",
       "2      1  800  4.00    True   False   False   False\n",
       "3      1  640  3.19   False   False   False    True\n",
       "4      0  520  2.93   False   False   False    True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "data = pd.concat([admissions, pd.get_dummies(admissions['rank'], prefix='rank')], axis=1)\n",
    "data = data.drop('rank', axis=1)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80699fb-c3ed-4b40-b73b-c91e637183d9",
   "metadata": {},
   "source": [
    "### Z-score standardization\n",
    "\n",
    "We used `Z-score standardization` on the `GRE` scores and `GPA` values to put them on a similar scale. Consider two students: one with `GRE = 320` and `GPA = 3.5`, another with `GRE = 160` and `GPA = 4.0`. Since `GRE` scores range from `130-170` while `GPAs` range from `0-4`, this difference in scales might confuse our model into thinking `GRE` scores are more important simply because they're bigger numbers.\n",
    "\n",
    "The code standardizes each value by finding how far it is from the average (subtracting the mean) and dividing by the standard deviation. After this process, both `GRE` and `GPA` values will typically center around `0 `and fall between `-3` and `+3`, indicating if a score is above or below average. For instance, a `GRE` of `330` might become `+2`, while a `GPA` of `2.5` might become `-1`. This transformation helps the model treat both measures fairly, regardless of their original scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9a77dafd-7a47-4649-aeec-18132b3311a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.798011</td>\n",
       "      <td>0.578348</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.625884</td>\n",
       "      <td>0.736008</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.837832</td>\n",
       "      <td>1.603135</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.452749</td>\n",
       "      <td>-0.525269</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.586063</td>\n",
       "      <td>-1.208461</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit       gre       gpa  rank_1  rank_2  rank_3  rank_4\n",
       "0      0 -1.798011  0.578348   False   False    True   False\n",
       "1      1  0.625884  0.736008   False   False    True   False\n",
       "2      1  1.837832  1.603135    True   False   False   False\n",
       "3      1  0.452749 -0.525269   False   False   False    True\n",
       "4      0 -0.586063 -1.208461   False   False   False    True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Z-score standardization\n",
    "for field in ['gre', 'gpa']:\n",
    "    mean, std = data[field].mean(), data[field].std()\n",
    "    data[field] = data[field].astype(np.float64)\n",
    "    data.loc[:, field] = (data[field] - mean) / std\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e06f9-fa65-4e9f-bcfe-3761c133dea3",
   "metadata": {},
   "source": [
    "### Spliting the data into train and test sets\n",
    "\n",
    "We're using this code to create a fair way to test how well our model will work with new data. The code starts with `np.random.seed(42)`, which ensures our random split stays consistent across runs, like using the same shuffle pattern for cards. We then use `np.random.choice` with `replace=False` to randomly select `90%` of our data rows, similar to picking `90` students from a class of `100` without repeating any selections.\n",
    "\n",
    "The data is split into training data (`90%`) and test data (`10%`), mimicking real-world model application. The larger portion teaches our model, while the smaller portion tests it - like how students learn from textbooks but are tested on different questions to ensure true understanding rather than memorization. This method helps ensure our model can handle new data effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1de3443c-8938-40e7-80ae-a2ee86cbef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (360, 7)\n",
      "test set shape: (40, 7)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "np.random.seed(42)\n",
    "\n",
    "sample = np.random.choice(data.index, size=int(len(data) * 0.9), replace=False)\n",
    "data, test_data = data.iloc[sample], data.drop(sample)\n",
    "\n",
    "print(f\"Training set shape: {data.shape}\")\n",
    "print(f\"test set shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191428dd-f065-4c2b-929e-5dc92111ea4f",
   "metadata": {},
   "source": [
    "### Separating our data into input features\n",
    "\n",
    "This code is separating our data into input features and target values that we want to predict. We create four key sets: our main `features` (all columns except `admit`), our main `targets` (just the `admit` column), and corresponding test versions (`features_test` and `targets_test`) from our test data. The `print` statements show us the dimensions of each set, helping us verify we've split everything correctly.\n",
    "\n",
    "Think of it like organizing a recipe: the features are your ingredients (like flour, sugar, eggs), and the target is what you're trying to make (like a cake). We split them into training sets (where we learn the recipe) and test sets (where we verify if we learned it correctly). The shapes tell us how many examples and characteristics we have in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "09f77361-b830-4558-8fc1-6e2fbda15126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (360, 6)\n",
      "Targets shape: (360,)\n",
      "Test features shape: (40, 6)\n",
      "Test targets shape: (40,)\n"
     ]
    }
   ],
   "source": [
    "# Split into features and targets\n",
    "features, targets = data.drop('admit', axis=1), data['admit']\n",
    "features_test, targets_test = test_data.drop('admit', axis=1), test_data['admit']\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")\n",
    "print(f\"Test features shape: {features_test.shape}\")\n",
    "print(f\"Test targets shape: {targets_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90617d9f-dda8-41ce-9b06-53acecc02b38",
   "metadata": {},
   "source": [
    "### Sigmoid function\n",
    "\n",
    "The `sigmoid` function helps convert any number into a probability between `0` and `1`. It works like a special calculator that takes any number and transforms it into this limited range. We use `np.array(x, dtype=float)` to ensure we're working with decimal numbers, then apply the formula `1 / (1 + np.exp(-x))` to create an S-shaped curve.\n",
    "\n",
    "When a number goes through this function, large positive numbers become close to `1`, large negative numbers become close to `0`, and `0` becomes exactly `0.5`. This transformation is crucial for logistic regression as it helps us interpret our results as probabilities of admission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1445f434-5c92-401b-8fb5-2035187a58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-np.array(x, dtype=float)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f4b57-da5b-4bb2-bf22-1f8fac1c0083",
   "metadata": {},
   "source": [
    "### Initialize `n_records`, `n_features` and `last_loss`\n",
    "We create two key variables: `n_records` and `n_features` to store the dimensions of our dataset, and initialize `last_loss` at `0` to track our model's prediction errors over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "768375dc-8ba5-40cd-b5fa-5ef49e99f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_records, n_features = features.shape\n",
    "last_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f341ae-9e10-4919-8b51-1d84a0d6f7a0",
   "metadata": {},
   "source": [
    "### Initialize weights\n",
    "\n",
    "The code initializes our model's `weights` using random numbers from a normal distribution, where we scale them by `1 / sqrt(n_features)`. This scaling helps prevent our initial predictions from being too extreme and allows for better learning during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d066774b-df70-4ee7-b665-e11a1be9ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30aedd-ca21-46e0-abaf-9cb33173be52",
   "metadata": {},
   "source": [
    "### Neural Network hyperparameters\n",
    "\n",
    "These two hyperparameters control our model's training process: `epochs` sets how many times we'll iterate through our data (in this case `1000` cycles), while `learnrate` of `0.5` determines how big our adjustments are when improving the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7f758341-18dd-468e-92b4-d92559006d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "learnrate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ca4c8-cce5-4785-9299-0b7aaf2e6fd8",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "This code runs the core training loop of our logistic regression model, performing iterative weight adjustments to improve admission predictions. The process loops through our data multiple times (epochs), making incremental improvements to find optimal prediction weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a0927488-06f2-4a66-b13c-4000ead2f87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2545249645145559\n",
      "Train loss:  0.20947756008222448\n",
      "Train loss:  0.20139454062371134\n",
      "Train loss:  0.19893736276429308\n",
      "Train loss:  0.1979702271254469\n",
      "Train loss:  0.19752222530389685\n",
      "Train loss:  0.19729138322092427\n",
      "Train loss:  0.1971634254018444\n",
      "Train loss:  0.1970887003886595\n",
      "Train loss:  0.19704335892544572\n"
     ]
    }
   ],
   "source": [
    "# Main training loop running 1000 times\n",
    "for e in range(epochs):\n",
    "    # Initialize array to store weight updates\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    # Loop through each student's data\n",
    "    for x, y in zip(features.values, targets):\n",
    "        \n",
    "        # Convert features to precise float numbers\n",
    "        x = np.array(x, dtype=np.float64)\n",
    "        # Convert target (admission result) to precise float\n",
    "        y = np.float64(y)\n",
    "        \n",
    "        # Calculate probability of admission\n",
    "        output = sigmoid(np.dot(weights, x))\n",
    "        \n",
    "        # Compute difference between actual and predicted\n",
    "        error = y - output\n",
    "        \n",
    "        # Calculate gradient for updating weights\n",
    "        error_term = error * output * (1 - output)\n",
    "        \n",
    "        # Add this sample's weight updates to total changes\n",
    "        del_w += error_term * x\n",
    "        \n",
    "    # Apply averaged weight updates\n",
    "    weights += (learnrate * del_w) / n_records\n",
    "    \n",
    "    # Every 100 epochs, monitor training progress\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        # Calculate current prediction error\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        # Store current loss for next comparison\n",
    "        last_loss = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb53e86e-9a6d-42f4-beb8-c3c526a2265a",
   "metadata": {},
   "source": [
    "### Calculate accuracy on test data\n",
    "\n",
    "Our trained model makes predictions on new test data by calculating admission probabilities through the `sigmoid` function, converting them to yes/no decisions at a `0.5` threshold, and comparing these against actual results to measure accuracy as a percentage of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "986d8152-a5c7-489c-bd07-ceef4e964c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "# Convert probabilities to binary predictions at 0.5 threshold\n",
    "predictions = tes_out > 0.5\n",
    "# Compute accuracy by comparing to actual admission results\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "# Display accuracy score to 3 decimal places\n",
    "print(f\"Prediction accuracy: {accuracy:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
